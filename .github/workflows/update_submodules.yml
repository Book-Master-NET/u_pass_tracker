name: Update Submodules with Real AI Documentation using Ollama

on:
  schedule:
    - cron: "0 */20 * * *"   # cada 20 horas
  workflow_dispatch:

permissions:
  contents: write
  pull-requests: write
  actions: read

jobs:
  # Job 1: Setup Ollama with optimizations
  setup-ollama:
    name: üöÄ Setup Ollama Environment
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          submodules: recursive
          fetch-depth: 0

      - name: Generate GitHub App Token
        id: app-token
        uses: tibdex/github-app-token@v2
        with:
          app_id: ${{ secrets.BOOK_MASTER_NET_GITHUB_APP_ID }}
          private_key: ${{ secrets.BOOK_MASTER_NET_GITHUB_APP_PRIVATE_KEY }}
          installation_retrieval_mode: repository
          installation_retrieval_payload: ${{ github.repository }}

      - name: Install Ollama
        run: |
          echo "üì¶ Installing Ollama..."
          curl -fsSL https://ollama.ai/install.sh | sh
          
          # Start Ollama service in background
          ollama serve &
          sleep 5
          echo "‚úÖ Ollama service started"

      - name: Download optimized model (Llama 3.2 3B or Phi-3)
        run: |
          echo "üîΩ Downloading optimized model..."
          # Use smaller, faster model for CI/CD
          ollama pull llama3.2:3b || ollama pull phi3:mini || ollama pull llama3:8b
          echo "‚úÖ Model downloaded successfully"

      - name: Verify Ollama installation
        run: |
          echo "üîç Verifying Ollama..."
          ollama list
          echo "‚úÖ Ollama verification complete"

      - name: Configure Git with App Token
        run: |
          git config user.name "fqmasterbot[app]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git config --global url."https://${{ steps.app-token.outputs.token }}@github.com/".insteadOf "https://github.com/"

  # Job 2: An√°lisis con Ollama optimizado
  analyze-with-ollama:
    name: üîç Real AI Analysis with Ollama
    runs-on: ubuntu-latest
    needs: setup-ollama
    timeout-minutes: 20
    outputs:
      has-changes: ${{ steps.detect-changes.outputs.changes }}
      ai-documentation: ${{ steps.ollama-analysis.outputs.documentation }}
    
    steps:
      - name: Generate GitHub App Token
        id: app-token
        uses: tibdex/github-app-token@v2
        with:
          app_id: ${{ secrets.BOOK_MASTER_NET_GITHUB_APP_ID }}
          private_key: ${{ secrets.BOOK_MASTER_NET_GITHUB_APP_PRIVATE_KEY }}
          installation_retrieval_mode: repository
          installation_retrieval_payload: ${{ github.repository }}

      - name: Checkout with submodules (using App Token)
        uses: actions/checkout@v4
        with:
          token: ${{ steps.app-token.outputs.token }}
          submodules: recursive
          fetch-depth: 0

      - name: Configure Git identity
        run: |
          git config user.name "fqmasterbot[app]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git config --global url."https://${{ steps.app-token.outputs.token }}@github.com/".insteadOf "https://github.com/"

      - name: Setup Ollama for analysis
        run: |
          echo "üöÄ Setting up Ollama for analysis..."
          curl -fsSL https://ollama.ai/install.sh | sh
          ollama serve &
          sleep 10
          
          # Download smaller, faster model
          ollama pull llama3.2:3b || ollama pull phi3:mini || {
            echo "‚ö†Ô∏è Failed to download optimized model, using fallback"
            ollama pull llama3:8b
          }

      - name: Update submodules and detect changes
        id: detect-changes
        run: |
          echo "üîÑ Updating submodules..."
          
          # Capturar estado antes
          git submodule status > submodule_before.txt
          
          # Actualizar subm√≥dulos con timeout
          timeout 300s git submodule update --remote --merge --progress || {
            echo "‚ö†Ô∏è Submodule update timed out, proceeding with partial updates"
          }
          
          # Capturar estado despu√©s
          git submodule status > submodule_after.txt
          
          # Detectar cambios
          if [[ -n "$(git status --porcelain)" ]]; then
            echo "changes=true" >> $GITHUB_OUTPUT
            
            # Crear archivo optimizado de cambios (limitado)
            echo "# Submodule Changes Summary for AI Analysis" > detailed_changes.md
            echo "Generated: $(date)" >> detailed_changes.md
            echo "" >> detailed_changes.md
            
            # Limitar a m√°ximo 5 subm√≥dulos para evitar overflow
            CHANGE_COUNT=0
            for submodule in $(git diff --name-only | head -5); do
              if [ -d "$submodule" ] && [ $CHANGE_COUNT -lt 5 ]; then
                echo "## Submodule: $submodule" >> detailed_changes.md
                
                cd "$submodule" 2>/dev/null || continue
                
                REPO_URL=$(git config --get remote.origin.url 2>/dev/null || echo "Unknown")
                CURRENT_BRANCH=$(git branch --show-current 2>/dev/null || echo "detached")
                LATEST_COMMIT=$(git log -1 --oneline 2>/dev/null || echo "No commits")
                
                echo "- Repository: $REPO_URL" >> ../detailed_changes.md
                echo "- Branch: $CURRENT_BRANCH" >> ../detailed_changes.md
                echo "- Latest: $LATEST_COMMIT" >> ../detailed_changes.md
                echo "" >> ../detailed_changes.md
                
                # Solo √∫ltimos 3 commits para mantener el prompt corto
                echo "### Recent commits:" >> ../detailed_changes.md
                git log --oneline -3 2>/dev/null | sed 's/^/- /' >> ../detailed_changes.md || echo "- No history" >> ../detailed_changes.md
                echo "" >> ../detailed_changes.md
                
                cd ..
                CHANGE_COUNT=$((CHANGE_COUNT + 1))
              fi
            done
            
            # Verificar tama√±o del archivo
            if [ $(wc -c < detailed_changes.md) -gt 2000 ]; then
              head -c 2000 detailed_changes.md > detailed_changes_trimmed.md
              mv detailed_changes_trimmed.md detailed_changes.md
              echo "... (trimmed for AI analysis)" >> detailed_changes.md
            fi
          else
            echo "changes=false" >> $GITHUB_OUTPUT
            echo "No changes detected" > detailed_changes.md
          fi

      - name: Generate optimized AI prompt
        if: steps.detect-changes.outputs.changes == 'true'
        run: |
          echo "üìù Generating optimized AI prompt..."
          
          cat > ai_prompt.txt << 'EOF'
          You are a senior software engineer. Analyze these Git submodule changes and provide a concise technical assessment.
          
          REQUIREMENTS:
          - Keep response under 1000 words
          - Focus on critical technical impacts
          - Provide clear risk levels (LOW/MEDIUM/HIGH)
          - Include actionable recommendations
          - Use markdown formatting
          
          CHANGES:
          EOF
          
          cat detailed_changes.md >> ai_prompt.txt
          
          echo "" >> ai_prompt.txt
          echo "GENERATE:" >> ai_prompt.txt
          echo "1. Executive Summary (2-3 sentences)" >> ai_prompt.txt
          echo "2. Technical Impact (bullet points)" >> ai_prompt.txt  
          echo "3. Risk Assessment (LOW/MEDIUM/HIGH with reasoning)" >> ai_prompt.txt
          echo "4. Recommendations (max 3 key actions)" >> ai_prompt.txt

      - name: Run optimized AI analysis with retries
        id: ollama-analysis
        if: steps.detect-changes.outputs.changes == 'true'
        run: |
          echo "ü§ñ Running optimized AI analysis..."
          
          # Function to run AI analysis with retry logic
          run_ai_analysis() {
            local attempt=$1
            local model=$2
            local timeout_duration=$3
            
            echo "üöÄ Attempt $attempt with model $model (timeout: ${timeout_duration}s)"
            
            if timeout ${timeout_duration}s ollama run $model --temperature 0.1 "$(cat ai_prompt.txt)" > raw_ai_output_$attempt.txt 2>&1; then
              echo "‚úÖ AI analysis successful with $model"
              return 0
            else
              echo "‚ùå AI analysis failed with $model (attempt $attempt)"
              return 1
            fi
          }
          
          # Try multiple models with increasing timeouts
          SUCCESS=false
          
          # Attempt 1: Fast model, short timeout
          if run_ai_analysis 1 "llama3.2:3b" 120; then
            cp raw_ai_output_1.txt raw_ai_output.txt
            SUCCESS=true
          # Attempt 2: Alternative fast model
          elif run_ai_analysis 2 "phi3:mini" 150; then
            cp raw_ai_output_2.txt raw_ai_output.txt
            SUCCESS=true
          # Attempt 3: Standard model, longer timeout
          elif run_ai_analysis 3 "llama3:8b" 240; then
            cp raw_ai_output_3.txt raw_ai_output.txt
            SUCCESS=true
          fi
          
          # Fallback if all attempts fail
          if [ "$SUCCESS" = false ]; then
            echo "‚ö†Ô∏è All AI analysis attempts failed. Generating fallback documentation."
            cat > raw_ai_output.txt << 'FALLBACK_EOF'
          # ü§ñ Technical Analysis Report
          
          ## Executive Summary
          Submodule updates detected. Manual review recommended due to AI analysis timeout.
          
          ## Technical Impact
          - Submodule dependencies updated to latest versions
          - Potential integration impacts require verification
          - Testing recommended before merge
          
          ## Risk Assessment: MEDIUM
          - **Reasoning**: Automated updates without full AI analysis
          - **Mitigation**: Thorough testing and code review required
          
          ## Recommendations
          1. **Run comprehensive tests** on updated dependencies
          2. **Manual code review** of submodule changes
          3. **Staging deployment** before production merge
          
          *Note: This is a fallback analysis due to AI processing constraints.*
          FALLBACK_EOF
          fi
          
          # Create final documentation
          echo "# ü§ñ AI-Powered Technical Analysis" > ai_documentation.md
          echo "> Generated using Ollama AI analysis" >> ai_documentation.md
          echo "> Timestamp: $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> ai_documentation.md
          echo "" >> ai_documentation.md
          
          cat raw_ai_output.txt >> ai_documentation.md
          
          echo "" >> ai_documentation.md
          echo "---" >> ai_documentation.md
          echo "*ü§ñ This analysis was generated using Ollama AI with automated fallback*" >> ai_documentation.md
          
          # Output for GitHub Actions (with size limit)
          if [ $(wc -c < ai_documentation.md) -gt 8000 ]; then
            head -c 8000 ai_documentation.md > ai_documentation_trimmed.md
            echo "... (output trimmed for GitHub Actions)" >> ai_documentation_trimmed.md
            mv ai_documentation_trimmed.md ai_documentation.md
          fi
          
          {
            echo "documentation<<EOF"
            cat ai_documentation.md
            echo "EOF"
          } >> $GITHUB_OUTPUT
          
          echo "‚úÖ AI analysis pipeline completed!"

      - name: Upload analysis artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ai-analysis-artifacts
          path: |
            detailed_changes.md
            ai_prompt.txt
            raw_ai_output*.txt
            ai_documentation.md
            submodule_before.txt
            submodule_after.txt

  # Job 3: Crear Pull Request con an√°lisis AI
  create-ai-pr:
    name: üìã Create AI-Powered Pull Request
    runs-on: ubuntu-latest
    needs: analyze-with-ollama
    if: needs.analyze-with-ollama.outputs.has-changes == 'true'
    timeout-minutes: 10
    
    steps:
      - name: Generate GitHub App Token
        id: app-token
        uses: tibdex/github-app-token@v2
        with:
          app_id: ${{ secrets.BOOK_MASTER_NET_GITHUB_APP_ID }}
          private_key: ${{ secrets.BOOK_MASTER_NET_GITHUB_APP_PRIVATE_KEY }}
          installation_retrieval_mode: repository
          installation_retrieval_payload: ${{ github.repository }}

      - name: Checkout repository (using App Token)
        uses: actions/checkout@v4
        with:
          token: ${{ steps.app-token.outputs.token }}
          submodules: recursive
          fetch-depth: 0

      - name: Configure Git for PR creation
        run: |
          git config user.name "fqmasterbot[app]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git config --global url."https://${{ steps.app-token.outputs.token }}@github.com/".insteadOf "https://github.com/"

      - name: Download analysis artifacts
        uses: actions/download-artifact@v4
        with:
          name: ai-analysis-artifacts
          path: ./

      - name: Update submodules before PR
        run: |
          echo "üîÑ Ensuring submodules are updated for PR..."
          git submodule update --remote --merge --progress || true
          git add . || true
          
          if [[ -n "$(git status --porcelain)" ]]; then
            git commit -m "chore: update submodules with AI analysis [skip ci]" || true
          fi

      - name: Create Pull Request with AI Analysis
        uses: peter-evans/create-pull-request@v5
        with:
          token: ${{ steps.app-token.outputs.token }}
          commit-message: "chore: update submodules with AI analysis [skip ci]"
          title: "ü§ñ AI-Analyzed Submodule Updates (Run #${{ github.run_number }})"
          body: |
            ${{ needs.analyze-with-ollama.outputs.ai-documentation }}
            
            ---
            
            ## üîß Technical Implementation Details
            - **AI Provider**: Ollama with optimized models
            - **Workflow Run**: #${{ github.run_number }}
            - **Analysis Type**: Multi-model AI with fallback
            - **Timestamp**: $(date -u '+%Y-%m-%d %H:%M:%S UTC')
            
            ## üìä AI Performance
            - **Models Tried**: llama3.2:3b ‚Üí phi3:mini ‚Üí llama3:8b
            - **Timeout Strategy**: Progressive timeouts (120s ‚Üí 150s ‚Üí 240s)
            - **Fallback**: Intelligent fallback documentation
            
            ## ‚úÖ Quality Assurance
            - Automated submodule validation
            - Multi-attempt AI analysis
            - Size-optimized prompts and outputs
            
            ---
            *ü§ñ This PR was created using an optimized AI analysis pipeline with intelligent fallbacks.*
          branch: ai-update-${{ github.run_number }}
          delete-branch: true
          reviewers: remr11
          assignees: remr11

  # Job 4: Enhanced status report
  report-status:
    name: üìä AI Analysis Report
    runs-on: ubuntu-latest
    needs: [setup-ollama, analyze-with-ollama, create-ai-pr]
    if: always()
    
    steps:
      - name: Generate comprehensive status report
        run: |
          echo "## ü§ñ Optimized AI Analysis Report"
          echo "**Run #${{ github.run_number }}** - $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
          echo ""
          
          echo "### üöÄ Ollama Setup"
          echo "- Status: ${{ needs.setup-ollama.result }}"
          echo "- Models: llama3.2:3b, phi3:mini, llama3:8b (fallback chain)"
          echo "- Optimization: ‚úÖ Fast models prioritized"
          echo ""
          
          echo "### üîç AI Analysis" 
          echo "- Status: ${{ needs.analyze-with-ollama.result }}"
          echo "- Changes Found: ${{ needs.analyze-with-ollama.outputs.has-changes }}"
          echo "- Strategy: ‚úÖ Multi-model with intelligent fallback"
          echo "- Timeout Handling: ‚úÖ Progressive timeouts implemented"
          echo ""
          
          echo "### üìã Pull Request"
          if [ "${{ needs.analyze-with-ollama.outputs.has-changes }}" == "true" ]; then
            echo "- Status: ${{ needs.create-ai-pr.result }}"
            echo "- AI Documentation: ‚úÖ Generated with reliability improvements"
            echo "- Authentication: ‚úÖ GitHub App Token"
          else
            echo "- Status: Skipped (no changes detected)"
          fi
          
          echo ""
          echo "### üéØ Optimizations Applied"
          echo "- ‚úÖ Smaller, faster AI models"
          echo "- ‚úÖ Progressive timeout strategy"
          echo "- ‚úÖ Intelligent fallback documentation"
          echo "- ‚úÖ Output size limits"
          echo "- ‚úÖ Retry logic with multiple models"
          echo "- ‚úÖ Optimized prompts"

  # Job 5: Cleanup
  cleanup:
    name: üßπ Cleanup
    runs-on: ubuntu-latest
    needs: report-status
    if: always()
    
    steps:
      - name: Cleanup Ollama and resources
        run: |
          echo "üßπ Cleaning up resources..."
          pkill ollama || true
          pkill -f "ollama serve" || true
          
          # Clean up any large temporary files
          rm -f /tmp/ollama* || true
          
          echo "‚úÖ Cleanup completed successfully"
